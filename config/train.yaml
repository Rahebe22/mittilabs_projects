## parameters for data loading and model specification
Train_Validate:

    # data loader parameters
    data_path: '/home/airg/rabedi/thesis/mittilabs/TrainingData' 
    log_dir: '/home/airg/rabedi/thesis/mittilabs/work_dir/train/logs'



    train_csv_name: '/home/airg/rabedi/thesis/mittilabs/TrainingData/train_cat.csv'

    data_size: 224  # Size of chips that is not buffered. (i.e., the size of labels)
    buffer: 0  # one_side_buffer
    buffer_comp: 0  # Buffer used when creating composite
    img_path_cols: ['image']
    label_path_col: 'label'
    label_group: [0,1,2,3,4,5]
    apply_normalization: True
    normal_strategy: "min_max"
    stat_procedure: 'lab'
    global_stats: null
    catalog_index: null
    trans: null
    parallel: null


    # explicilty pass the default values for the following **kwargs
    scale_factor: (0.75, 1.5)
    crop_strategy: "center"
    rotation_degree: (-180, -90, 90, 180)
    #bshiift_subs:  # this was not defined and used in datatorch.py
    sigma_range: [0.03, 0.07]
    br_range: [-0.02, 0.02]
    contrast_range: [0.9, 1.2]
    bshift_gamma_range: (0.2, 2.0)
    patch_shift: True
    downfactor: 32
    clip_val: 0
    nodata: []


    train_batch: 32
    validate_batch: 10


    # model compiler parameters
    model: unet_att_d 
    model_compiler_buffer: 0
    class_mapping: {0: 'non-field', 1: 'field'} #, 2: 'field boundary'}
    model_working_dir: '/home/airg/rabedi/thesis/mittilabs/work_dir/train/'
    model_out_dir: ''
    gpu_devices: [0]
    use_sync_bn: False
    model_init_type: "kaiming"
    params_init: null #'/home/airg/rabedi/thesis/anydiff/work_dir/train/best_model.pth'
    freeze_params: 'None' #list(range(43))
    n_classes: 2
    channels: 3
        
    
    model_kwargs: {filter_config: [64, 128, 256, 512, 1024, 2048],
                   block_num: [2, 2, 2, 2, 2, 2], 
                   dropout_rate: 0.1, 
                   dropout_type: 'traditional', 
                   upmode: 'deconv_2', 
                   use_skipAtt: False}
    

    epoch: 80
    optimizer_name: SAM
    learning_rate_init: 0.01
    learning_rate_policy: "StepLR"
    criterion: LocallyWeightedTverskyFocalLoss()
    momentum: 0.95
    resume: False
    checkpoint_interval: 20
    resume_epoch: null
    early_stopping_patience: 10 
    min_delta: 0.001
    warmup_period: 10


    val_metric_fname: train_metrics_mittilabs.csv
    model_out_dir:  '/home/airg/rabedi/thesis/mittilabs/work_dir/train/'

Test:
  separate_test_csv: null
  saved_params: null
    
  
  
  
